{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Infant Mortality\n",
    "\n",
    "One of my primary tasks at the Indiana Department of Health was, given the data from a child's birth certificate, determine the probability of their death.  After linking the birth and death certificates, this involved simply giving a report of the descriptive statitistics of infant deaths (defined as deaths of children who were born who died one year or younger) followed by a logistic regression.  I was never asked to make a more detailed predictive model, but as this is a project for my portfolio and not for my job, we can have a little fun.  Below I will first do a logistic regression, and then try a decision tree, a neural network, and a random forest.  *Note to readers:  This is a work in progress.  So far I've only done the logistic regression...next step is to test it.  This page will be updated weekly.*\n",
    "\n",
    "\n",
    "While the data from IDOH are de-identified and I could conceivably use those, I'll elect to make my own dataset by splitting ten thousand individuals between three races (purple, blue, and green), two genders (positive and negative), and four ages (young, teen, adult, senior).\n",
    "\n",
    "But first, let's import some necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Population and Assign Probabilities\n",
    "\n",
    "In the next session we'll create our population and assign the probabilities of death.\n",
    "\n",
    "### Create Population\n",
    "\n",
    "As mentioned above, we'll have three races (purple, blue, and green), four ages (young, teen, adult, senior), and at risk of reinforcing the gender binary, two genders (positive and negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# population will be 70% blue, 20% green, 10% purple.\n",
    "race_list = [\"blue\"]*7000\n",
    "for i in range(2000):\n",
    "    race_list.append(\"green\")\n",
    "for i in range(1000):\n",
    "    race_list.append(\"purple\")\n",
    "\n",
    "# population will be 50% positive and 50% negative.\n",
    "gender_list = [\"positive\",\"negative\"]*5000\n",
    "\n",
    "# population will be 20% young, adult, and senior, and 40% teen.\n",
    "age_list = [\"young\",\"teen\",\"teen\",\"adult\",\"senior\"]*2000\n",
    "\n",
    "# assemble these lists into a data frame using the dictionary method:\n",
    "population = pd.DataFrame(\n",
    "                            { 'race':race_list,\n",
    "                              'gender':gender_list,\n",
    "                              'age':age_list }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign Probabilities\n",
    "\n",
    "We'll make the probability of death 50% for purple, 10% for green, and 100% for purple.  Note that these are *much higher* than the probabilities of *actual* infant death, but for the purposes of this exercise we want to refrain from having too unbalanced a target set.  Just trying to show basic technique, here, and not dig into the specifics of how to deal with unbalanced sets.  (Perhaps that'll be a project for later.)\n",
    "\n",
    "At any rate, the probability for positive gender will be 90%, for negative gender will be 80%, and for young 60%, 80% for teenagers, 90% for adult, and 100% for seniors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>total_probs</th>\n",
       "      <th>final_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blue</td>\n",
       "      <td>positive</td>\n",
       "      <td>young</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blue</td>\n",
       "      <td>negative</td>\n",
       "      <td>teen</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>blue</td>\n",
       "      <td>positive</td>\n",
       "      <td>teen</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blue</td>\n",
       "      <td>negative</td>\n",
       "      <td>adult</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "      <td>positive</td>\n",
       "      <td>senior</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   race    gender     age  total_probs  final_outcome\n",
       "0  blue  positive   young         0.27              0\n",
       "1  blue  negative    teen         0.32              0\n",
       "2  blue  positive    teen         0.36              0\n",
       "3  blue  negative   adult         0.36              0\n",
       "4  blue  positive  senior         0.45              0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assign race probabilities\n",
    "race_probs = [0.5]*7000\n",
    "for i in range(2000):\n",
    "    race_probs.append(0.1)\n",
    "for i in range(1000):\n",
    "    race_probs.append(1.0)\n",
    "race_probs = np.array(race_probs)\n",
    "\n",
    "# assign gender probabilities\n",
    "gender_probs = [0.9,0.8]*5000\n",
    "gender_probs = np.array(gender_probs)\n",
    "\n",
    "# assign age probabilities\n",
    "age_probs = [0.6, 0.8, 0.8, 0.9, 1.0]*2000\n",
    "age_probs = np.array(age_probs)\n",
    "\n",
    "# figure out total probabilities, add column to data frame\n",
    "total_probs = race_probs*gender_probs*age_probs\n",
    "population['total_probs'] = total_probs\n",
    "\n",
    "# now assign each individual to an outcome, based on probability\n",
    "final_outcome = np.array( [0]*10000 )\n",
    "for i in range(10000):\n",
    "    if total_probs[i]>0.5:\n",
    "        final_outcome[i] = 1\n",
    "    else:\n",
    "        final_outcome[i] = 0\n",
    "population['final_outcome'] = final_outcome\n",
    "\n",
    "# take a look at the population\n",
    "population.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive Statistics\n",
    "\n",
    "Let's do some quick and dirty descriptive statistics on the dataset.  We have already determined the proportion of race, age, and gender, so we'll not worry about that.  How many are dead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dead: 900\n",
      "Percentage of population 9.0\n"
     ]
    }
   ],
   "source": [
    "x = population['final_outcome'].sum()\n",
    "N = 10000\n",
    "\n",
    "print(\"Number of dead:\",x)\n",
    "print(\"Percentage of population\",100*x/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     race    gender     age\n",
      "0  purple  positive   young\n",
      "1  purple  negative    teen\n",
      "2  purple  positive    teen\n",
      "3  purple  negative   adult\n",
      "4  purple  positive  senior\n",
      "Number of dead: 900\n",
      "Total population breakdown:\n",
      "race    gender    age   \n",
      "purple  positive  teen      0.222222\n",
      "        negative  teen      0.222222\n",
      "        positive  young     0.111111\n",
      "                  senior    0.111111\n",
      "                  adult     0.111111\n",
      "        negative  senior    0.111111\n",
      "                  adult     0.111111\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Proportion gender:\n",
      "gender\n",
      "positive    0.555556\n",
      "negative    0.444444\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Proportion age:\n",
      "age\n",
      "teen      0.444444\n",
      "senior    0.222222\n",
      "adult     0.222222\n",
      "young     0.111111\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# create a data frame of the deceased population consisting of race, gender, and age columns\n",
    "pop_deceased = population[population['final_outcome']==1].reset_index(drop=True).drop(['total_probs','final_outcome'],axis=1)\n",
    "print(pop_deceased.head())\n",
    "\n",
    "N = len(pop_deceased)\n",
    "print(\"Number of dead:\",N)\n",
    "\n",
    "print(\"Total population breakdown:\")\n",
    "print( pop_deceased.value_counts()/N )\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Proportion gender:\")\n",
    "print( pop_deceased.value_counts('gender')/N )\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Proportion age:\")\n",
    "print( pop_deceased.value_counts('age')/N )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all of the deceased are of race purple, 5/9ths are positively gendered, 4/9ths are teenagers, 2/9ths are seniors and adults, and 1/9th are young."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "Now let's perform a logistic regression on the dataset, the first and simplest form of machine learning we can apply here.\n",
    "\n",
    "Because we're working with categorical data, we can't simply plug the numbers in directly and let 'er rip.  Insetad we need to encode them into dummy variables.  For this we need LabelEncoder() and OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>total_probs</th>\n",
       "      <th>final_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      race  gender  age  total_probs  final_outcome\n",
       "0        0       1    3         0.27              0\n",
       "1        0       0    2         0.32              0\n",
       "2        0       1    2         0.36              0\n",
       "3        0       0    0         0.36              0\n",
       "4        0       1    1         0.45              0\n",
       "...    ...     ...  ...          ...            ...\n",
       "9995     2       0    3         0.48              0\n",
       "9996     2       1    2         0.72              1\n",
       "9997     2       0    2         0.64              1\n",
       "9998     2       1    0         0.81              1\n",
       "9999     2       0    1         0.80              1\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = population.select_dtypes(exclude=['number']) \\\n",
    "              .apply(LabelEncoder().fit_transform) \\\n",
    "              .join(population.select_dtypes(include=['number']))\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in our first step, we have encoded race so that blue is 0, green is 1, and purple is 2.  Gender is encoded so that 0 is negative and 1 is positive.  Age is encoded so that 0 is adult, 1 is senior, 2 is teen, and 3 is young.\n",
    "\n",
    "Next we use one hot encoder and run the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.20961704]\n",
      "[[-5.60976893 -4.56132434  7.96147624 -3.04261357  0.83299653  0.72513262\n",
      "   0.72513262  0.7862183  -4.44610058]]\n"
     ]
    }
   ],
   "source": [
    "pop_subset = x[['race','gender','age']]\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(pop_subset)\n",
    "onehotlabels = enc.transform(pop_subset).toarray()\n",
    "\n",
    "model = LogisticRegression(solver='liblinear',random_state=0) \\\n",
    "        .fit(onehotlabels,x['final_outcome'])\n",
    "\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have our model, approximately:\n",
    "$$y = -2.2 - 5.6\\beta_{blue} - 4.6\\beta_{green} + 8.0\\beta_{purple} - 3.0\\beta_{negative} + 0.8\\beta_{positive} + 0.7\\beta_{adult} + 0.7\\beta_{senior} + 0.8\\beta_{teen} - 4.4\\beta_{young}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note to readers:  This is a work in progress.  So far I've only done the logistic regression...next step is to test it.  This page will be updated weekly.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
